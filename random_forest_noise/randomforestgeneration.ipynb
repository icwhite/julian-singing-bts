{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pretty_midi if needed\n",
    "!pip install -q pretty_midi\n",
    "!pip install -q music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "import pretty_midi\n",
    "from IPython.display import Audio\n",
    "from collections import defaultdict\n",
    "from music21 import converter, chord, stream, tempo\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files in the target directory\n",
    "all_midi_files = [f for f in os.listdir('/root/class_stuff/musicml/assign2/midi_files/') if f.endswith('.mid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_midi_files[0])\n",
    "print(len(all_midi_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02853d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instruments(midi_file):\n",
    "    \"\"\"\n",
    "    Extracts the instruments from a MIDI file.\n",
    "    \"\"\"\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    return [instrument.name for instrument in midi_data.instruments if instrument.is_drum is False]\n",
    "\n",
    "dataroot = '/root/class_stuff/musicml/assign2/midi_files/'\n",
    "\n",
    "all_instruments = []\n",
    "num_instruments = []\n",
    "only_plpr = []\n",
    "for midi_file in all_midi_files:\n",
    "    full_path = os.path.join(dataroot, midi_file)\n",
    "    instruments = get_instruments(full_path)\n",
    "    format_instrument_names = [inst.lower() for inst in instruments]\n",
    "    all_instruments.extend(format_instrument_names)\n",
    "    num_instruments.append(len(instruments))\n",
    "    if 'piano right' in format_instrument_names and 'piano left' in format_instrument_names:\n",
    "        only_plpr.append(midi_file)\n",
    "        if len(format_instrument_names) != 2:\n",
    "            print(f\"File {midi_file} has more than two instruments: {format_instrument_names}\") \n",
    "\n",
    "print(f'Tota number of MIDI files: {len(all_midi_files)}')\n",
    "unique_instruments, counts = np.unique(all_instruments, return_counts = True)\n",
    "for i, inst in enumerate(unique_instruments):\n",
    "    print(f\"{inst}: {counts[i]}\")\n",
    "\n",
    "print(np.mean(num_instruments))\n",
    "print(len(only_plpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, chord, stream, tempo, pitch\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "def extract_chords_as_array(\n",
    "    midi_path,\n",
    "    interval=0.1,\n",
    "    playback: str = None   # options: 'original', 'chords', 'both', or None\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      chords_list            # your original list of chord-events\n",
    "      normalized_chords_list # same, but each chord’s pitches_midi all equal\n",
    "      interval_array         # at each time-step, lists of active chords’ MIDI lists\n",
    "      normalized_audio       # waveform of the normalized-chord MIDI\n",
    "    \"\"\"\n",
    "    score = converter.parse(midi_path)\n",
    "    chords = score.chordify()\n",
    "    mm = score.recurse().getElementsByClass(tempo.MetronomeMark).first()\n",
    "    bpm = mm.number if mm else 120\n",
    "    # print(f\"Detected BPM: {bpm}\")\n",
    "    duration = chords.highestTime\n",
    "\n",
    "    time_steps = np.arange(0, duration, interval)\n",
    "    chord_stream = stream.Part()\n",
    "    chord_stream.insert(0, tempo.MetronomeMark(number=bpm))\n",
    "    chords_list = []\n",
    "\n",
    "    last_chord = None\n",
    "    last_offset = 0.0\n",
    "\n",
    "    all_pitches = []\n",
    "    for t in time_steps:\n",
    "        elems = chords.flat.getElementsByOffset(t, mustBeginInSpan=False)\n",
    "        this_chord = next((e for e in elems if isinstance(e, chord.Chord)), None)\n",
    "        if this_chord is not None:\n",
    "            if last_chord is None or set(this_chord.normalOrder) != set(last_chord.normalOrder):\n",
    "                if last_chord:\n",
    "                    dur = t - last_offset\n",
    "                    last_chord.quarterLength = dur\n",
    "                    chord_stream.insert(last_offset, last_chord)\n",
    "                    chords_list.append({\n",
    "                        'offset':      last_offset,\n",
    "                        'duration':    dur,\n",
    "                        'pitches_midi': [p.midi for p in last_chord.pitches],\n",
    "                        'pitches_name': [p.nameWithOctave for p in last_chord.pitches]\n",
    "                    })\n",
    "                last_chord = chord.Chord(this_chord)  # copy\n",
    "                last_offset = t\n",
    "\n",
    "    if last_chord:\n",
    "        dur = duration - last_offset\n",
    "        last_chord.quarterLength = dur\n",
    "        chord_stream.insert(last_offset, last_chord)\n",
    "        chords_list.append({\n",
    "            'offset':      last_offset,\n",
    "            'duration':    dur,\n",
    "            'pitches_midi': [p.midi for p in last_chord.pitches],\n",
    "            'pitches_name': [p.nameWithOctave for p in last_chord.pitches]\n",
    "        })\n",
    "\n",
    "\n",
    "    chordified_fp = 'chord_progression_clean.mid'\n",
    "    chord_stream.write('midi', fp=chordified_fp)\n",
    "\n",
    "    def synth_and_display(midi_fp, label):\n",
    "        pm = pretty_midi.PrettyMIDI(midi_fp)\n",
    "        audio = pm.synthesize(fs=44100)\n",
    "        print(f\"Playing {label}...\")\n",
    "        display(Audio(audio, rate=44100, autoplay=True))\n",
    "        return audio\n",
    "\n",
    "    # if playback in ('original', 'both'):\n",
    "    #     _ = synth_and_display(midi_path, 'original MIDI')\n",
    "    # if playback in ('chords',   'both'):\n",
    "    #     _ = synth_and_display(chordified_fp, 'chordified progression')\n",
    "\n",
    "    # --- 3) Build normalized_chords_list ---\n",
    "    normalized_chords_list = []\n",
    "    for evt in chords_list:\n",
    "        orig = evt['pitches_midi']\n",
    "        if orig:\n",
    "            m = int(round(np.mean(orig)))\n",
    "            name = pitch.Pitch(m).nameWithOctave\n",
    "            norm_midi = [m] * len(orig)\n",
    "            norm_names = [name] * len(orig)\n",
    "        else:\n",
    "            norm_midi = []\n",
    "            norm_names = []\n",
    "        normalized_chords_list.append({\n",
    "            'offset':       evt['offset'],\n",
    "            'duration':     evt['duration'],\n",
    "            'pitches_midi': norm_midi,\n",
    "            'pitches_name': norm_names\n",
    "        })\n",
    "\n",
    "    interval_array = []\n",
    "    for t in time_steps:\n",
    "        # find all events covering t\n",
    "        active = [\n",
    "            evt['pitches_midi']\n",
    "            for evt in chords_list\n",
    "            if evt['offset'] <= t < evt['offset'] + evt['duration']\n",
    "        ]\n",
    "        interval_array.append(active)\n",
    "\n",
    "    norm_stream = stream.Part()\n",
    "    norm_stream.insert(0, tempo.MetronomeMark(number=bpm))\n",
    "    for evt in normalized_chords_list:\n",
    "        c = chord.Chord(evt['pitches_midi'])\n",
    "        c.quarterLength = evt['duration']\n",
    "        norm_stream.insert(evt['offset'], c)\n",
    "\n",
    "    norm_fp = 'normalized_chord_progression.mid'\n",
    "    norm_stream.write('midi', fp=norm_fp)\n",
    "    normalized_audio = pretty_midi.PrettyMIDI(norm_fp).synthesize(fs=44100)\n",
    "    # print(\"Playing normalized-pitch progression…\")\n",
    "    # display(Audio(normalized_audio, rate=44100, autoplay=True))\n",
    "\n",
    "    return chords_list, normalized_chords_list, interval_array, normalized_audio\n",
    "\n",
    "test_file = dataroot + only_plpr[0]\n",
    "\n",
    "# chord_array = extract_chords_as_array(test_file, playback=None)\n",
    "\n",
    "# 2) Play only the chordified version:\n",
    "# chord_array = extract_chords_as_array(test_file, playback='chords')\n",
    "\n",
    "# 3) Play both original then chordified:\n",
    "chord_array, interval_array, per_step, normalized_audio = extract_chords_as_array(test_file, playback='both')\n",
    "\n",
    "# 4) Play only original:\n",
    "# chord_array = extract_chords_as_array(test_file, playback='original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c444d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chord_array[:10])\n",
    "chord_pitch_dict = {}\n",
    "for chord in chord_array:\n",
    "    midi_pitches = chord['pitches_midi']\n",
    "    pitch_names = chord['pitches_name']\n",
    "\n",
    "    for i, pitch in enumerate(midi_pitches):\n",
    "        if pitch_names[i] not in chord_pitch_dict.keys():\n",
    "            chord_pitch_dict[pitch_names[i]] = [pitch]\n",
    "        else:\n",
    "            if pitch not in chord_pitch_dict[pitch_names[i]]:   \n",
    "                chord_pitch_dict[pitch_names[i]].append(pitch)\n",
    "\n",
    "print(chord_pitch_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f285a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_data = pretty_midi.PrettyMIDI(test_file)\n",
    "audio_data = midi_data.synthesize(fs=44100)\n",
    "Audio(audio_data, rate=44100, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63dc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# only_plpr_info = {}\n",
    "# successful = 0\n",
    "# for file in only_plpr:\n",
    "#     try:\n",
    "#         chord_array, interval_array, per_step, _ = extract_chords_as_array(dataroot + file, playback='both')\n",
    "#         only_plpr_info[file] = {'chord_array': chord_array,\n",
    "#                                 'interval_array': interval_array,\n",
    "#                                 'per_step': per_step}\n",
    "#         successful+= 1\n",
    "#         if successful % 20 == 0 or successful == 1:\n",
    "#             with open('data.json', 'w') as f:\n",
    "#                 json.dump(only_plpr_info, f, indent=4)\n",
    "\n",
    "#     except:\n",
    "#         print(f'Extracting midi from {file} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('full_data.json', 'r') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999cbc4",
   "metadata": {},
   "source": [
    "Count all unique chords and the number of times they appear in the dataset. To narrow the space of possible chords, we restrict our random forest to only the chords that appear greater than the overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_array(arr):\n",
    "    str_arr = []\n",
    "    for ele in arr:\n",
    "        str_arr.append(str(ele))\n",
    "    return str_arr\n",
    "\n",
    "chord_pitch_dict = {}\n",
    "for i, itms in data.items():\n",
    "    chord_array = itms['chord_array']\n",
    "    for chord in chord_array:\n",
    "        midi_pitches = chord['pitches_midi']\n",
    "        pitch_names = chord['pitches_name']\n",
    "\n",
    "        for i, pitch in enumerate(midi_pitches):\n",
    "            if pitch_names[i] not in chord_pitch_dict.keys():\n",
    "                chord_pitch_dict[pitch_names[i]] = [pitch, 1]\n",
    "            else:\n",
    "                if pitch not in chord_pitch_dict[pitch_names[i]]:   \n",
    "                    chord_pitch_dict[pitch_names[i]].append(pitch)\n",
    "                else:\n",
    "                    chord_pitch_dict[pitch_names[i]][1] += 1\n",
    "\n",
    "print(chord_pitch_dict)\n",
    "print(len(chord_pitch_dict))\n",
    "print(\"Filtered chord pitch dict:\")\n",
    "filteredChordPitch = {}\n",
    "totalCounts = []\n",
    "for chord, counts in chord_pitch_dict.items():\n",
    "    totalCounts.append(counts[1])\n",
    "    if counts[1] < 7000:\n",
    "        continue\n",
    "    filteredChordPitch[chord] = counts\n",
    "print(filteredChordPitch)\n",
    "print(len(filteredChordPitch))\n",
    "print(np.mean(totalCounts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af63960",
   "metadata": {},
   "source": [
    "Get a reversed key-value dictionary for ease of use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredPitchChord = {}\n",
    "for chord, pitch in filteredChordPitch.items():\n",
    "    filteredPitchChord[pitch[0]] = chord\n",
    "\n",
    "# Make sure they are the same size.\n",
    "assert len(filteredPitchChord) == len(filteredChordPitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06cd76d",
   "metadata": {},
   "source": [
    "Now, we look at the actual time stepped progression of chords. First, lets gather some statistics about how long arrays are in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_lens = []\n",
    "chord_totals = []\n",
    "\n",
    "filtered_lens = []\n",
    "filtered_totals = []\n",
    "\n",
    "for i, itms in data.items():\n",
    "    chord_array = itms['per_step']\n",
    "    simplified_chord_array = [chord[0] if len(chord) > 0 else [] for chord in chord_array]\n",
    "\n",
    "    filtered_simplified_chord_array = []\n",
    "    for chords in simplified_chord_array:\n",
    "        new_chord_arr = []\n",
    "        for chord in chords:\n",
    "            if chord in filteredPitchChord.keys():\n",
    "                new_chord_arr.append(chord)\n",
    "        filtered_simplified_chord_array.append(new_chord_arr)\n",
    "\n",
    "    for chords in simplified_chord_array:\n",
    "        chord_lens.append(len(chords))\n",
    "    chord_totals.append(len(simplified_chord_array))\n",
    "\n",
    "    for chords in filtered_simplified_chord_array:\n",
    "        filtered_lens.append(len(chords))\n",
    "    filtered_totals.append(len(filtered_simplified_chord_array))\n",
    "\n",
    "print(f'Unfiltered chords average length: {np.mean(chord_totals)}, average number of chords per time step: {np.mean(chord_lens)}')\n",
    "print(f'Filtered chords average length: {np.mean(filtered_totals)}, average number of chords per time step: {np.mean(filtered_lens)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309eeb75",
   "metadata": {},
   "source": [
    "Similar to the chords, we make this a tractable task for a random forest by truncating the chord lengths. Lets start with just 600 so things run fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c384e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHORD_LENGTH = 600 # Since we chunk by .1, this is about 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allChordDatapoints = []\n",
    "filtered_lens = []\n",
    "filtered_totals = []\n",
    "for i, itms in data.items():\n",
    "    chord_array = itms['per_step']\n",
    "    simplified_chord_array = [chord[0] if len(chord) > 0 else [] for chord in chord_array]\n",
    "\n",
    "    filtered_simplified_chord_array = []\n",
    "    for chords in simplified_chord_array[:MAX_CHORD_LENGTH]:\n",
    "        new_chord_arr = []\n",
    "        for chord in chords:\n",
    "            if chord in filteredPitchChord.keys():\n",
    "                new_chord_arr.append(chord)\n",
    "        filtered_simplified_chord_array.append(new_chord_arr)\n",
    "\n",
    "    for chords in simplified_chord_array:\n",
    "        chord_lens.append(len(chords))\n",
    "    chord_totals.append(len(simplified_chord_array))\n",
    "\n",
    "    for chords in filtered_simplified_chord_array:\n",
    "        filtered_lens.append(len(chords))\n",
    "    filtered_totals.append(len(filtered_simplified_chord_array))\n",
    "    allChordDatapoints.append(filtered_simplified_chord_array)\n",
    "\n",
    "print(f'Filtered chords average length: {np.mean(filtered_totals)}, average number of chords per time step: {np.mean(filtered_lens)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0976ba",
   "metadata": {},
   "source": [
    "Now lets make some ear cancer. We mask out all chords except the immediate next chord (next chord prediction like teacher-forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1155f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the available chords: These are our classes\n",
    "print(filteredChordPitch.keys())\n",
    "print(len(filteredChordPitch.keys()))\n",
    "MASK_CHORD = [[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = []\n",
    "targets = []\n",
    "last_chord_added = \"\"\n",
    "for datapoint in allChordDatapoints:\n",
    "    chord_datapoint = []\n",
    "    chord_masks = len(datapoint)\n",
    "    for chord in datapoint:\n",
    "        # Add a chord\n",
    "        chord_datapoint.append(chord)\n",
    "        chord_masks -= 1\n",
    "        # Mask all the rest of the chords and add it to add data\n",
    "        datapoint_copy = chord_datapoint.copy()\n",
    "        datapoint_copy += MASK_CHORD * chord_masks\n",
    "        # We skip duplicate chords to avoid letting the random forest just always output the most recent chord.\n",
    "        if last_chord_added == chord:\n",
    "            last_chord_added = \"\"\n",
    "            continue\n",
    "        allData.append(datapoint_copy)\n",
    "        targets.append(chord)\n",
    "        last_chord_added = chord\n",
    "# print(allData[0])\n",
    "# print(targets[0])\n",
    "print(len(allData))\n",
    "\n",
    "allData = []\n",
    "targets = []\n",
    "last_chord_added = \"\"\n",
    "for datapoint in allChordDatapoints:\n",
    "    chord_datapoint = []\n",
    "    chord_masks = len(datapoint)\n",
    "    for chord in datapoint:\n",
    "        # Add a chord\n",
    "        chord_datapoint.append(chord)\n",
    "        chord_masks -= 1\n",
    "        # Mask all the rest of the chords and add it to add data\n",
    "        datapoint_copy = chord_datapoint.copy()\n",
    "        datapoint_copy += MASK_CHORD * chord_masks\n",
    "        # We skip duplicate chords to avoid letting the random forest just always output the most recent chord.\n",
    "        if last_chord_added == chord:\n",
    "            last_chord_added = \"\"\n",
    "            continue\n",
    "        allData.append(datapoint_copy)\n",
    "        targets.append(chord)\n",
    "        last_chord_added = chord\n",
    "print(allData[101])\n",
    "print(targets[101])\n",
    "print(len(allData))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([43, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing   import MultiLabelBinarizer\n",
    "from sklearn.multioutput     import MultiOutputClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics         import classification_report\n",
    "\n",
    "\n",
    "CLASS_LIST = [43, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
    "NUM_CLASSES = len(CLASS_LIST)\n",
    "\n",
    "def extract_features(seqs):\n",
    "    feat_dicts = []\n",
    "    for seq in seqs:\n",
    "        # flatten out all non-mask values\n",
    "        values = [v for sub in seq for v in sub if v != -1]\n",
    "        cnt = Counter(values)\n",
    "        # build a dict { \"count_0\":…, \"count_1\":…, … }\n",
    "        feat_dicts.append({f\"count_{c}\": cnt.get(c, 0) for c in CLASS_LIST})\n",
    "    return feat_dicts\n",
    "\n",
    "def extract_features_decay(seqs, gamma=0.8):\n",
    "    feat_dicts = []\n",
    "    N = len(CLASS_LIST)\n",
    "    for seq in seqs:\n",
    "        T = len(seq)\n",
    "        # Initialize decay scores to zero\n",
    "        decay_scores = {c: 0.0 for c in CLASS_LIST}\n",
    "        \n",
    "        # For each time‐slice t, add gamma^(T-1 - t) to each chord in that slice\n",
    "        for t, slice_ in enumerate(seq):\n",
    "            weight = (gamma ** (T - 1 - t))\n",
    "            for c in slice_:\n",
    "                if c != -1:\n",
    "                    decay_scores[c] += weight\n",
    "        \n",
    "        # Flatten into a feature dict\n",
    "        d = {f\"decay_{c}\": decay_scores[c] for c in CLASS_LIST}\n",
    "        feat_dicts.append(d)\n",
    "    \n",
    "    return feat_dicts\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "X = vec.fit_transform(extract_features_decay(allData))\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=CLASS_LIST)\n",
    "Y = mlb.fit_transform(targets)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "base_rf = RandomForestClassifier(\n",
    "    n_estimators=1500,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "clf = MultiOutputClassifier(base_rf)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(\n",
    "    y_test, y_pred,\n",
    "    target_names=[str(c) for c in mlb.classes_]\n",
    "))\n",
    "\n",
    "pred_sets = mlb.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_chord_staleness(last_chords):\n",
    "    if len(last_chords) < 3:\n",
    "        return False\n",
    "    chord1 = last_chords[-1]\n",
    "    chord2 = last_chords[-2]\n",
    "    chord3 = last_chords[-3]\n",
    "    if len(chord1) != len(chord2) or len(chord2) != len(chord3):\n",
    "        return False\n",
    "    if len(chord1) == 1:\n",
    "        all_chords = []\n",
    "        for chord in last_chords:\n",
    "            all_chords.append(chord[0])\n",
    "        if len(np.unique(all_chords)) != 1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        for i, chord in enumerate(chord2):\n",
    "            if chord != chord1[i] or chord != chord3[i]:\n",
    "                return False\n",
    "    return True\n",
    "        \n",
    "        \n",
    "# Initialize an empty vector\n",
    "# last_chords = [random.choice(CLASS_LIST)]\n",
    "last_chords =  [50, 52, 59, 64, 68]\n",
    "sanity_check = [[66], [66], [66], [66], [66], [68], [68], [68], [69], [69], [50, 52, 59, 64, 68]]\n",
    "X_seq = sanity_check + [[-1] for _ in range(600 - len(sanity_check))]\n",
    "last_chords_added = []\n",
    "for i in range(600):\n",
    "    X_seq[i] = last_chords\n",
    "    last_chords_added.append(last_chords)\n",
    "    print(X_seq[i])\n",
    "    if get_chord_staleness(last_chords_added):\n",
    "        last_chords = [random.choice(CLASS_LIST)]\n",
    "        last_chords_added = []\n",
    "        print(\"Last random here\")\n",
    "    else:\n",
    "        X = vec.fit_transform(extract_features_decay([X_seq]))\n",
    "        proba_list = clf.predict_proba(X)\n",
    "        last_chords = []\n",
    "        for j, probs in enumerate(proba_list):\n",
    "            if probs[0][1] > .5:\n",
    "                last_chords.append(CLASS_LIST[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_full_mask_one_per_slot(clf, vec, mlb, MAX_SLOTS: int) -> list[list[int]]:\n",
    "    X_seq = [[-1] for _ in range(MAX_SLOTS)]\n",
    "\n",
    "    for slot_idx in range(MAX_SLOTS):\n",
    "        feat_dicts = extract_features([X_seq])  # returns list of dicts\n",
    "        X0 = vec.transform(feat_dicts)          # shape = (1, n_features)\n",
    "\n",
    "        # predict_proba returns a list of length = n_classes; each entry is (1×2) array\n",
    "        proba_list = clf.predict_proba(X0)\n",
    "        pos_probs = np.array([arr[0, 1] for arr in proba_list])\n",
    "\n",
    "        best_idx = np.argmax(pos_probs)         # index of most‐likely class\n",
    "        best_label = mlb.classes_[best_idx]      # actual class value, e.g. 43, 48, etc.\n",
    "\n",
    "        X_seq[slot_idx] = [best_label]\n",
    "\n",
    "    return X_seq\n",
    "\n",
    "\n",
    "def fill_full_mask_multi_per_slot(clf, vec, mlb, MAX_SLOTS: int,\n",
    "                                  threshold: float = 0.2) -> list[list[int]]:\n",
    "    X_seq = [[-1] for _ in range(MAX_SLOTS)]\n",
    "\n",
    "    for slot_idx in range(MAX_SLOTS):\n",
    "        feat_dicts = extract_features([X_seq])\n",
    "        X0 = vec.transform(feat_dicts)\n",
    "\n",
    "        proba_list = clf.predict_proba(X0)\n",
    "        pos_probs = np.array([arr[0, 1] for arr in proba_list])  # shape=(n_classes,)\n",
    "\n",
    "        chosen_indices = np.where(pos_probs >= threshold)[0].tolist()\n",
    "        if not chosen_indices:\n",
    "            # force one if nothing crosses the threshold\n",
    "            best_idx = np.argmax(pos_probs)\n",
    "            chosen_indices = [best_idx]\n",
    "\n",
    "        predicted_labels = [mlb.classes_[i] for i in chosen_indices]\n",
    "        X_seq[slot_idx] = predicted_labels\n",
    "\n",
    "    return X_seq\n",
    "\n",
    "\n",
    "MAX_SLOTS = 60\n",
    "\n",
    "# 1) One‐label‐per‐slot\n",
    "filled_one = fill_full_mask_one_per_slot(clf, vec, mlb, MAX_SLOTS)\n",
    "print(\"Hypothesized sequence (one‐label per slot):\")\n",
    "print(filled_one)\n",
    "\n",
    "# 2) Multi‐label per slot with threshold=0.2\n",
    "filled_multi = fill_full_mask_multi_per_slot(clf, vec, mlb, MAX_SLOTS, threshold=0.2)\n",
    "print(\"\\nHypothesized sequence (multi‐label per slot, T=0.2):\")\n",
    "print(filled_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b41916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_full_mask_multi_per_slot_fast(\n",
    "    clf,\n",
    "    counts_vec: np.ndarray,\n",
    "    class_to_feat_idx: dict[int,int],\n",
    "    all_classes: np.ndarray,\n",
    "    MAX_SLOTS: int,\n",
    "    threshold: float = 0.2\n",
    ") -> list[list[int]]:\n",
    "    \"\"\"\n",
    "    For each slot, pick every class whose P(label=1) >= threshold.\n",
    "    If none exceed threshold, forcibly pick the single class with max P(label=1).\n",
    "    \"\"\"\n",
    "\n",
    "    completed_slots: list[list[int]] = []\n",
    "    clf_proba = clf.predict_proba\n",
    "\n",
    "    for slot_idx in range(MAX_SLOTS):\n",
    "        X0 = counts_vec.reshape(1, -1)\n",
    "\n",
    "        # Get the list of (1×2) arrays, one per class:\n",
    "        proba_list = clf_proba(X0)\n",
    "        pos_probs   = np.fromiter((arr[0, 1] for arr in proba_list),\n",
    "                                  dtype=float, count=len(all_classes))\n",
    "\n",
    "        # Pick all class‐indices with prob >= threshold\n",
    "        chosen_idxs = np.where(pos_probs >= threshold)[0].tolist()\n",
    "\n",
    "        if not chosen_idxs:\n",
    "            # If nothing passes threshold, fallback to argmax\n",
    "            best_idx = int(np.argmax(pos_probs))\n",
    "            chosen_idxs = [best_idx]\n",
    "\n",
    "        # Convert those indices → actual class values, e.g. [43, 60, 79]\n",
    "        chosen_labels = [int(all_classes[i]) for i in chosen_idxs]\n",
    "        completed_slots.append(chosen_labels)\n",
    "\n",
    "        # Update counts_vec for all chosen labels\n",
    "        for i in chosen_idxs:\n",
    "            label = int(all_classes[i])\n",
    "            feat_col = class_to_feat_idx[label]\n",
    "            counts_vec[feat_col] += 1\n",
    "\n",
    "    return completed_slots\n",
    "\n",
    "def fill_full_mask_one_per_slot_fast(\n",
    "    clf,\n",
    "    counts_vec: np.ndarray,\n",
    "    class_to_feat_idx: dict[int,int],\n",
    "    all_classes: np.ndarray,\n",
    "    MAX_SLOTS: int\n",
    ") -> list[list[int]]:\n",
    "    \"\"\"\n",
    "    For each of the MAX_SLOTS, pick exactly one class: the one with highest P(label=1).\n",
    "    counts_vec is a numpy array of length = n_features, initially all zeros.\n",
    "    class_to_feat_idx maps each label (e.g. 43) to its column in counts_vec.\n",
    "    all_classes is mlb.classes_ (shape = (n_classes,)).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Start with a fully‐masked representation: we won't actually store X_seq,\n",
    "    #    but we will build the output list-of-lists incrementally.\n",
    "    completed_slots: list[list[int]] = []\n",
    "\n",
    "    # Local references for speed:\n",
    "    clf_proba = clf.predict_proba  # bound method to get probabilities\n",
    "\n",
    "    for slot_idx in range(MAX_SLOTS):\n",
    "        # --- A) We already have counts_vec from previous slots. Just reshape it.\n",
    "        X0 = counts_vec.reshape(1, -1)  # shape = (1, n_features)\n",
    "\n",
    "        # --- B) Compute positive‐class probabilities for each of the n_classes\n",
    "        #     Because clf is MultiOutputClassifier(RF), predict_proba(X0) returns\n",
    "        #     a list of length = n_classes, where each entry is a (1×2) array\n",
    "        #     for “P(class_i = 0)” vs “P(class_i = 1)”.\n",
    "        proba_list = clf_proba(X0)\n",
    "        #    proba_list[i][0,1] == P(label_i = 1) for class index i.\n",
    "\n",
    "        # Build a (n_classes,) float array of “positive” probabilities:\n",
    "        pos_probs = np.fromiter((arr[0, 1] for arr in proba_list),\n",
    "                                dtype=float, count=all_classes)\n",
    "\n",
    "        # --- C) Find the argmax index\n",
    "        best_idx   = int(np.argmax(pos_probs))  # index in [0 .. n_classes-1]\n",
    "        best_label = int(all_classes[best_idx])  # e.g. 43 or 48, etc.\n",
    "\n",
    "        # --- D) Record it as our “filled” subarray for slot_idx\n",
    "        completed_slots.append([best_label])\n",
    "\n",
    "        # --- E) Update counts_vec in-place: increment the feature “count_<best_label>”\n",
    "        feat_col = class_to_feat_idx[best_label]\n",
    "        counts_vec[feat_col] += 1\n",
    "\n",
    "        # move on to next slot…\n",
    "\n",
    "    return completed_slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(vec.vocabulary_)  # e.g. 34 if you have 34 classes\n",
    "class_to_feat_idx = {\n",
    "    c: vec.vocabulary_[f\"count_{c}\"]\n",
    "    for c in CLASS_LIST\n",
    "}\n",
    "all_classes = mlb.classes_  # e.g. array([43,48,49,…,81])\n",
    "\n",
    "counts_vec = np.zeros((n_features,), dtype=int)\n",
    "MAX_SLOTS  = 600  # or however many subarray positions you expect\n",
    "\n",
    "\n",
    "seq_one_label = fill_full_mask_one_per_slot_fast(\n",
    "    clf,\n",
    "    counts_vec.copy(),        # make a fresh copy if you want to re-use the same initial state\n",
    "    class_to_feat_idx,\n",
    "    all_classes,\n",
    "    MAX_SLOTS\n",
    ")\n",
    "\n",
    "# (B) Possibly multiple labels per slot (threshold = 0.2)\n",
    "seq_multi_label = fill_full_mask_multi_per_slot_fast(\n",
    "    clf,\n",
    "    counts_vec.copy(),\n",
    "    class_to_feat_idx,\n",
    "    all_classes,\n",
    "    MAX_SLOTS,\n",
    "    threshold=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) Number of “count_<c>” features in your DictVectorizer:\n",
    "n_features = len(vec.vocabulary_)  # should equal len(CLASS_LIST)\n",
    "\n",
    "# 2) Build a direct mapping: class_value → column‐index in vec\n",
    "#    (Recall: when you did `vec.fit(...)`, your feature‐keys were like \"count_43\", \"count_48\", …)\n",
    "class_to_feat_idx = {\n",
    "    c: vec.vocabulary_[f\"count_{c}\"]\n",
    "    for c in CLASS_LIST\n",
    "}\n",
    "\n",
    "# 3) We’ll keep a 1D NumPy array of length = n_features that stores,\n",
    "#    at any time, how many times each “count_<c>” has appeared so far.\n",
    "counts_vec = np.zeros((n_features,), dtype=int)\n",
    "\n",
    "# 4) For convenience, pull out mlb.classes_ just once\n",
    "all_classes = mlb.classes_   # e.g. array([43,48,49,…,81])\n",
    "n_classes   = len(all_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
